version: '3'

services:
  fhir:
    depends_on:
      - mongo
    build:
      context: .
      dockerfile: Dockerfile
      args:
        NODE_ENV: development
    environment:
      SERVER_PORT: 3000
      MONGO_DB_NAME: fhir
      MONGO_URL: 'mongodb://mongo:27017?appName=fhir-server'
      AUDIT_EVENT_MONGO_DB_NAME: fhir
      AUDIT_EVENT_MONGO_URL: mongodb://mongo:27017
      RESOURCE_SERVER: http://localhost:3000/
      AUTH_SERVER_URI: http://myauthzserver.com
      CLIENT_ID: client
      CLIENT_SECRET: secret
      AUTH_CONFIGURATION_URI: https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yV7wvD4xD/.well-known/openid-configuration
      AUTH_JWKS_URL: https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yV7wvD4xD/.well-known/jwks.json
      AUTH_CODE_FLOW_URL: https://bwell-dev.auth.us-east-1.amazoncognito.com
      REDIRECT_TO_LOGIN: 1
      MAX_INDEX_NAME_LENGTH: 65
      ENV: local
      MONGO_TIMEOUT: 30000
      LOGLEVEL: 'DEBUG'
      ENABLE_GRAPHQL: 1
      NODE_ENV: 'development'
      EXTERNAL_AUTH_JWKS_URLS: 'https://cognito-idp.us-east-1.amazonaws.com/us-east-1_e4iVm1J4X/.well-known/jwks.json, https://cognito-idp.us-east-1.amazonaws.com/us-east-1_o71QMdxTG/.well-known/jwks.json,https://icanbwell.okta.com/oauth2/v1/keys'
      SET_INDEX_HINTS: 0
      CREATE_INDEX_ON_COLLECTION_CREATION: 1
      #      HASH_REFERENCE: 1
      RETURN_BUNDLE: '1'
      USE_TWO_STEP_SEARCH_OPTIMIZATION: '0'
      LOG_EXCLUDE_RESOURCES: 'Person,Patient'
      STREAM_RESPONSE: '1'
      LOG_STREAM_STEPS: '0'
      ENABLE_EVENTS_KAFKA: '1'
      ENABLE_BULK_EXPORT_KAFKA_EVENTS: '1'
      ENABLE_KAFKA_HEALTHCHECK: '1'
      KAFKA_CLIENT_ID: 'fhir-server'
      KAFKA_URLS: 'kafka:9092'
      KAFKA_MAX_RETRY: 3
      PARTITION_RESOURCES: 'AuditEvent'
      AUTH_CUSTOM_USERNAME: "preferred_username"
      AUTH_CUSTOM_GROUP: "groups"
      AUTH_CUSTOM_SCOPE: "custom:scope"
      VALIDATE_SCHEMA: "1"
      PERSON_MATCHING_SERVICE_URL: "https://person-matching.dev.bwell.zone/$$match"
      WHITELIST: "https://embeddable-sandbox.cdn.apollographql.com,http://localhost:5051,http://localhost:4000"
      GRIDFS_RESOURCES: "DocumentReference"
      ENABLE_ACCESS_TAG_UPDATE: '0'
      ENABLE_GRAPHQL_PLAYGROUND: '1'
      ENABLE_GRAPHQLV2_PLAYGROUND: '1'
      ENABLE_GRAPHQLV2: '1'
      ENABLE_CONSENTED_PROA_DATA_ACCESS: '1'
      ENABLE_HIE_TREATMENT_RELATED_DATA_ACCESS: '1'
      FHIR_VALIDATION_URL: 'http://hapi-fhir-server:8080/fhir'
      ENABLE_STATS_ENDPOINT: '1'
      FHIR_SERVER_UI_URL: 'http://localhost:5051'
      FHIR_ADMIN_UI_URL: 'http://localhost:4000'
      REDIRECT_TO_NEW_UI: '1'
      KAFKAJS_NO_PARTITIONER_WARNING: '1'
      ENABLE_BULK_EXPORT: '1'
      ENABLE_MEMORY_CHECK: '1'
      CONTAINER_MEM_REQUEST: 1000000000
      NO_OF_REQUESTS_PER_POD: 10
      ENABLE_VULCAN_IG_QUERY: 'true'
    ports:
      - '3000:3000'
    volumes:
      - ./src:/srv/src/src
      - ./package.json:/srv/src/package.json
      - ./yarn.lock:/srv/src/yarn.lock
    command: yarn run dev
    healthcheck:
      test: [ 'CMD-SHELL', 'wget --spider --quiet localhost:3000/health || exit 1' ]

  mongo:
    image: mongo:8.0.4
    ports:
      - '27017:27017'
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh mongo:27017/test --quiet

  #  mongoclient:
  #    image: imranq2/mongoclient-aws:0.1.8
  #    ports:
  #      - '3010:3000'
  #    environment:
  #      MONGOCLIENT_DEFAULT_CONNECTION_URL: mongodb://mongo:27017

  zookeeper:
    image: zookeeper:3.9.1
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    restart: on-failure
    healthcheck:
      test: [ 'CMD-SHELL', 'echo ruok | nc -w 2 zookeeper 2181' ]

  kafka:
    image: bitnami/kafka:3.5.1
    ports:
      - '9092:9092'
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKAJS_NO_PARTITIONER_WARNING=1
    depends_on:
      - zookeeper
    healthcheck:
      test:
        [
          'CMD',
          'bash',
          '-c',
          'unset',
          'JMX_PORT',
          ';',
          'kafka-topics.sh',
          '--zookeeper',
          'zookeeper:2181',
          '--list',
        ]

  # kafkaUI:
  #   image: provectuslabs/kafka-ui
  #   ports:
  #     - '9000:8080'
  #   environment:
  #     - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
  #     - 'JVM_OPTS=-Xms32M -Xmx64M'
  #     - SERVER_SERVLET_CONTEXT_PATH=/

  hapi-fhir-server:
    image: hapiproject/hapi:v6.10.1
    container_name: hapi-fhir-server
    environment:
      - hapi.fhir.enable_repository_validating_interceptor=true
      - hapi.fhir.ig_runtime_upload_enabled=true
      - hapi.fhir.local_base_urls=https://hapi.fhir.org/baseR4,https://fhir.simplifier.net/bwellFHIRProfiles
    ports:
      - "3001:8080"

  elasticsearch:
    #    image: bitnami/elasticsearch:7.9.3  # AWS Elastic Search supports upto 7.9
    # using OpenDistro for best compatibility with AWS Managed ElasticSearch:
    # https://opendistro.github.io/for-elasticsearch/downloads.html
    image: opensearchproject/opensearch:2.12.0
    container_name: elasticsearch
    environment:
      - cluster.name=odfe-cluster
      - node.name=elasticsearch
      - discovery.type=single-node
      #      - cluster.initial_master_nodes=elasticsearch
      - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM
      - network.host=0.0.0.0 # required if not using the demo security configuration
      #      - opendistro_security.disabled=true
      - cluster.routing.allocation.disk.threshold_enabled=false
      - plugins.security.ssl.http.enabled=false
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=UujbDM76i6ZKjHZn88dN
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536 # maximum number of open files for the Elasticsearch user, set to at least 65536 on modern systems
        hard: 65536
    volumes:
      - es_data:/usr/share/opensearch/data:delegated
    #      - ./conf/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:cached
    ports:
      - '9200:9200'
      - '9600:9600' # required for Performance Analyzer
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail https://admin:admin@localhost:9200/_cluster/health --insecure || exit 1" ]

volumes:
  mongo_data:
  es_data:
